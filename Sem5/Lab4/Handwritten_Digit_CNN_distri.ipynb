{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKUFAZb7JZz0"
      },
      "source": [
        "# Handwritten Digit recognition using CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyL-RC3WJZz9"
      },
      "source": [
        "# import the libararies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nQfGJt9lJZz_",
        "outputId": "b5cda43c-91d5-4877-9ec5-19dff4391dea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "(60000, 28, 28) (60000,)\n",
            "(10000, 28, 28) (10000,)\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gklr0dPDJZ0F"
      },
      "source": [
        "# Preprocessing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jMvFhEyVJZ0G",
        "outputId": "f08b8c8a-7dfd-4aca-d4c1-86ce2007e9a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ],
      "source": [
        "num_classes=10\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train = x_train/255\n",
        "x_test = x_test/255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9VyjoYuJZ0H"
      },
      "source": [
        "# Create the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EcQETJCJZ0I"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4x0FaNyvJZ0J"
      },
      "source": [
        "This code defines a convolutional neural network (CNN) architecture for the MNIST dataset, suitable for image classification tasks. The model consists of convolutional layers, pooling layers, dropout layers, and fully connected layers, and is compiled with appropriate loss function, optimizer, and metrics.\n",
        "\n",
        "Understanding the default values of the parameters in different functions calls will help you.\n",
        "\n",
        "<b>Hyperparameter Setting</b>: <br>\n",
        "`batch_size`: <br>\n",
        "Determines the number of samples processed in a single batch during training. A larger batch size can speed up training but might require more memory. <br>\n",
        "\n",
        "`num_classes`: <br>\n",
        "Specifies the number of output classes, which is 10 for the MNIST dataset (digits 0-9). <br>\n",
        "\n",
        "`epochs`: <br>\n",
        "Defines the number of times the entire dataset is passed through the network during training.\n",
        "\n",
        "<b>Model Architecture</b>: <br>\n",
        "`Sequential Model`: <br>\n",
        "Creates a sequential model, where layers are added sequentially. <br>\n",
        "\n",
        "<b>Convolutional Layers</b>: <br>\n",
        "`Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape)`:<br>\n",
        "* Adds a 2D convolutional layer with 32 filters, each of size 3x3.\n",
        "* ses the ReLU activation function to introduce non-linearity.\n",
        "* Specifies the input shape of the images (it's already defined).\n",
        "\n",
        "`Conv2D(64, (3, 3), activation='relu')`: <br>\n",
        "Adds another convolutional layer with 64 filters of size 3x3, also using ReLU activation. <br>\n",
        "\n",
        "<b>Pooling Layer</b>: <br>\n",
        "`MaxPooling2D(pool_size=(2, 2))`: <br>\n",
        "Downsamples the feature maps by taking the maximum value in 2x2 patches. This reduces the dimensionality and computational cost. <br>\n",
        "\n",
        "<b>Dropout Layer</b>: <br>\n",
        "`Dropout(0.25)`: <br>\n",
        "Randomly sets 25% of the input units to 0 during training. This helps prevent overfitting by introducing noise and making the model more robust. <br>\n",
        "\n",
        "<b>Flatten Layer</b>: <br>\n",
        "Flattens the 2D feature maps into a 1D vector. <br>\n",
        "\n",
        "<b>Dense Layers</b>: <br>\n",
        "`Dense(256, activation='relu')`: <br>\n",
        "Adds a fully connected layer with 256 units, using ReLU activation. <br>\n",
        "\n",
        "`Dense(num_classes, activation='softmax')`: <br>\n",
        "Adds a final fully connected layer with 10 units (equal to the number of classes) and uses the softmax activation function to produce probability distributions for each class. <br>\n",
        "\n",
        "<b>Model Compilation</b>: <br>\n",
        "<b>Loss Function</b>: <br>\n",
        "`keras.losses.categorical_crossentropy` is used as the loss function, which is appropriate for multi-class classification problems. <br>\n",
        "\n",
        "<b>Optimizer</b>:  <br>\n",
        "`keras.optimizers.Adadelta()` is used as the optimization algorithm. Adadelta is an adaptive learning rate algorithm that automatically adjusts the learning rate during training. <br>\n",
        "\n",
        "<b>Metrics</b>: <br>\n",
        "`accuracy` is used as the metric to evaluate the model's performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vLD35Q8xJZ0L",
        "outputId": "e99477ee-5f0b-4c0f-8647-5177ebee3aad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 10\n",
        "# START YOUR CODE HERE\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 10\n",
        "# START YOUR CODE HERE\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3,3),activation='relu',input_shape=input_shape))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='Adadelta', metrics=['accuracy'])\n",
        "# END YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3SCuQwEJZ0M"
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-ZIMAEcTJZ0N",
        "outputId": "5a146506-47b3-4b6e-9eae-09e0de658bde",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 397ms/step - accuracy: 0.1343 - loss: 2.2770 - val_accuracy: 0.3519 - val_loss: 2.2061\n",
            "Epoch 2/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 378ms/step - accuracy: 0.2773 - loss: 2.1968 - val_accuracy: 0.6193 - val_loss: 2.0966\n",
            "Epoch 3/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 375ms/step - accuracy: 0.4271 - loss: 2.0868 - val_accuracy: 0.7154 - val_loss: 1.9394\n",
            "Epoch 4/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 369ms/step - accuracy: 0.5315 - loss: 1.9366 - val_accuracy: 0.7451 - val_loss: 1.7229\n",
            "Epoch 5/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 367ms/step - accuracy: 0.5986 - loss: 1.7301 - val_accuracy: 0.7619 - val_loss: 1.4585\n",
            "Epoch 6/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 370ms/step - accuracy: 0.6433 - loss: 1.4903 - val_accuracy: 0.7858 - val_loss: 1.1955\n",
            "Epoch 7/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 372ms/step - accuracy: 0.6719 - loss: 1.2785 - val_accuracy: 0.8056 - val_loss: 0.9832\n",
            "Epoch 8/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 370ms/step - accuracy: 0.6981 - loss: 1.1028 - val_accuracy: 0.8230 - val_loss: 0.8310\n",
            "Epoch 9/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 375ms/step - accuracy: 0.7285 - loss: 0.9657 - val_accuracy: 0.8380 - val_loss: 0.7241\n",
            "Epoch 10/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 374ms/step - accuracy: 0.7412 - loss: 0.8829 - val_accuracy: 0.8468 - val_loss: 0.6475\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has successfully trained\n",
            "Saving the model as mnist.h5\n"
          ]
        }
      ],
      "source": [
        "hist=model.fit(x_train,y_train,batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(x_test, y_test))\n",
        "print(\"The model has successfully trained\")\n",
        "model.save('mnist.h5')\n",
        "print(\"Saving the model as mnist.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZX5i8EyUJZ0O"
      },
      "source": [
        "# Evaluate the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGu_JvrMJZ0O"
      },
      "source": [
        "The code snippet evaluates the trained CNN model on the test dataset and prints the test loss and accuracy. These metrics provide insights into the model's performance and help assess its ability to generalize to unseen data.\n",
        "\n",
        "`score = model.evaluate(x_test, y_test, verbose=0)`:\n",
        "\n",
        "* `model.evaluate`: <br>\n",
        "This function evaluates the model's performance on a given dataset.\n",
        "\n",
        "* `x_test`: <br>\n",
        "The input data (images) from the test set.\n",
        "\n",
        "* `y_test`: <br>\n",
        "The corresponding true labels for the test set.\n",
        "\n",
        "* `verbose=0`: <br>\n",
        "This argument suppresses the progress bar that is typically displayed during evaluation, making the output more concise.\n",
        "\n",
        "* The function returns a list containing the loss value and any specified metrics. In this case, since we've specified `metrics=['accuracy']`, the list will contain the test loss and test accuracy.\n",
        "\n",
        "`print('Test loss:', score[0])`: <br>\n",
        "This line prints the test loss, which is the first element in the score list. It indicates how well the model predicts the correct class for the test data. A lower loss value generally indicates better performance.\n",
        "\n",
        "`print('Test accuracy:', score[1])`: <br>\n",
        "This line prints the test accuracy, which is the second element in the score list. It represents the percentage of correct classifications on the test set. A higher accuracy indicates better performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "AxBfPZJ_JZ0P",
        "outputId": "892b2716-6182-4600-ce87-11450d65fba9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.6475410461425781\n",
            "Test accuracy: 0.8468000292778015\n"
          ]
        }
      ],
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "nlJPe3r4JZ0R",
        "outputId": "84b27476-8948-4bb3-e3c7-aad36992f98a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m320\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9216\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │       \u001b[38;5;34m2,359,552\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m2,570\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9216</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,552</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,570</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,142,816\u001b[0m (27.25 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,142,816</span> (27.25 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,380,938\u001b[0m (9.08 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,380,938</span> (9.08 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m4,761,878\u001b[0m (18.17 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,761,878</span> (18.17 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNejaBVeJZ0S"
      },
      "source": [
        "# Create GUI to predict digits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "MJ6ZtHwTJZ0S"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "from tkinter import *\n",
        "import tkinter as tk\n",
        "import win32gui\n",
        "from PIL import ImageGrab, Image\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mRqYjMbYJZ0T"
      },
      "outputs": [],
      "source": [
        "model = load_model('mnist.h5')\n",
        "def predict_digit(img):\n",
        "    #resize image to 28x28 pixels\n",
        "    img = img.resize((28,28))\n",
        "    #convert rgb to grayscale\n",
        "    img = img.convert('L')\n",
        "    img = np.array(img)\n",
        "    #reshaping to support our model input and normalizing\n",
        "    img = img.reshape(1,28,28,1)\n",
        "    img = img/255.0\n",
        "    #predicting the class\n",
        "    res = model.predict([img])[0]\n",
        "    print(np.argmax(res))\n",
        "    print(max(res))\n",
        "    return np.argmax(res), max(res)\n",
        "class App(tk.Tk):\n",
        "    def __init__(self):\n",
        "        tk.Tk.__init__(self)\n",
        "        self.x = self.y = 0\n",
        "        # Creating elements\n",
        "        self.canvas = tk.Canvas(self, width=300, height=300, bg = \"white\", cursor=\"cross\")\n",
        "        self.label = tk.Label(self, text=\"Thinking..\", font=(\"Helvetica\", 48))\n",
        "        self.classify_btn = tk.Button(self, text = \"Recognise\", command = self.classify_handwriting)\n",
        "        self.button_clear = tk.Button(self, text = \"Clear\", command = self.clear_all)\n",
        "        # Grid structure\n",
        "        self.canvas.grid(row=0, column=0, pady=2, sticky=W, )\n",
        "        self.label.grid(row=0, column=1,pady=2, padx=2)\n",
        "        self.classify_btn.grid(row=1, column=1,pady=2, padx=2)\n",
        "        self.button_clear.grid(row=1, column=0, pady=2)\n",
        "        #self.canvas.bind(\"<Motion>\", self.start_pos)\n",
        "        self.canvas.bind(\"<B1-Motion>\", self.draw_lines)\n",
        "    def clear_all(self):\n",
        "        self.canvas.delete(\"all\")\n",
        "    def classify_handwriting(self):\n",
        "        HWND = self.canvas.winfo_id() # get the handle of the canvas\n",
        "        rect = win32gui.GetWindowRect(HWND) # get the coordinate of the canvas\n",
        "        im = ImageGrab.grab(rect)\n",
        "        digit, acc = predict_digit(im)\n",
        "        self.label.configure(text= str(digit)+', '+ str(int(acc*100))+'%')\n",
        "    def draw_lines(self, event):\n",
        "        self.x = event.x\n",
        "        self.y = event.y\n",
        "        r=8\n",
        "        self.canvas.create_oval(self.x-r, self.y-r, self.x + r, self.y + r, fill='black')\n",
        "app = App()\n",
        "mainloop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4PTlHowXJZ0U"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the model\n",
        "model = tf.keras.models.load_model('mnist.h5')\n",
        "\n",
        "# Load MNIST data\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_test = np.expand_dims(x_test, -1) / 255.0  # Normalize and add channel dimension\n",
        "\n",
        "# Test the model with some test images\n",
        "for i in range(10):\n",
        "    img = x_test[i]\n",
        "    label = y_test[i]\n",
        "    img = np.expand_dims(img, 0)  # Add batch dimension\n",
        "    prediction = model.predict(img)[0]\n",
        "    predicted_class = np.argmax(prediction)\n",
        "    probability = np.max(prediction)\n",
        "\n",
        "    # Plot the image and prediction\n",
        "    plt.imshow(img[0, :, :, 0], cmap='gray')\n",
        "    plt.title(f'Label: {label}, Prediction: {predicted_class}, Probability: {probability:.2f}')\n",
        "    plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}